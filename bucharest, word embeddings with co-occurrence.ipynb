{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In <font color=\"red\">bucharest</font>, i'll examine omer's songs...\n",
    "\n",
    "\n",
    "# with simple text algorithms..... simple viz.........and........... \n",
    "# <font color=\"green\" size=6>clojure!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO numpy, no matplotlib....no python!!:\n",
    "with:\n",
    "1.  [core.matrix](https://github.com/mikera/core.matrix), array programming\n",
    "2. [vega](https://vega.github.io/vega/) (awesome DSL) and little bit [incanter](https://github.com/incanter/incanter), for viz, graphs\n",
    "3. clojure.test, [clojure.test.check](https://github.com/clojure/test.check), clojure.spec for example/property based testing (QuickCHECKKK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEGIN:\n",
    "\n",
    "### let's grab omer's songs with JSoup (javas scraping lib) & Java interop (calling java code from clojure) into memory:\n",
    "<figure class=\"half\" style=\"display:flex\">\n",
    "    <img src=\"omer2.png\" width=400>\n",
    "    <img src=\"omer3.png\" width=400>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "clojure.lang.LazySeq\n",
      "total scraped songs: 67\n",
      "==========================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{:title \"Tel Aviv\", :text \"She feels that her luck has opened up She met a manly man and a rajal 1 And she'll whisper to him, what will she whisper to him? 'Take me on the camel' I'm your beauty You're my beast Welcome to the Middle East Tel Aviv, ya habibi 2, Tel Aviv Look how many lirdim 3 there are around Telling me 'hi, hi' At night 'wai, wai' And well done, Tel Aviv Sun rises in the white city And he's being stared at from every corner And she knows, what does she know? He'll run away from her in a second I'm your beauty You're my beast Welcome to the Middle East Tel Aviv, ya habibi 2, Tel Aviv Look how many lirdim 3 there are around Telling me 'hi, hi' At night 'wai, wai' And well done, Tel Aviv I have it going up, up, up and not down\"}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "; =================================\n",
    "(require '[clojupyter.misc.helper :as helper]\n",
    "         '[clojupyter.misc.display :as display])\n",
    "(helper/add-dependencies '[org.jsoup/jsoup \"1.7.3\"])\n",
    "(import (org.jsoup Jsoup)\n",
    "        (org.jsoup.select Elements)\n",
    "        (org.jsoup.nodes Element))\n",
    "; =================================\n",
    "\n",
    "(def base-url \"https://lyricstranslate.com\")\n",
    "\n",
    "(defn get-page [url]\n",
    "  (.get (Jsoup/connect url)))\n",
    "\n",
    "(defn get-elems [page css]\n",
    "  (.select page css))\n",
    "\n",
    "(defn extract-links [url]\n",
    "  (for [e (get-elems (get-page url) \"a[href]\")\n",
    "        :when (and (= (.attr e \"class\") \"lang\")\n",
    "                   (or (= (.text e) \"English\")\n",
    "                       (= (.text e) \"#1\")))]\n",
    "    (str base-url (.attr e \"href\"))))\n",
    "\n",
    "(defn extract-song [url]\n",
    "  (let [elems (get-elems (get-page url) \"div#songtranslation > .translate-node-text\")\n",
    "        title (.text (get-elems elems \".title-h2\"))\n",
    "        text (.text (get-elems elems \".ltf > .par\"))]\n",
    "  {:title title\n",
    "   :text text}))\n",
    "\n",
    "(def omer-url (str base-url \"/en/omer-adam-lyrics.html\"))\n",
    "\n",
    "(defn scrape-omer []\n",
    "  (for [song-url (extract-links omer-url)]\n",
    "    (extract-song song-url)))\n",
    "\n",
    "; =================================\n",
    "(def scraped-songs (scrape-omer))\n",
    "(println \"==========================================================\")\n",
    "(println (type scraped-songs))\n",
    "(println \"total scraped songs:\" (count scraped-songs))\n",
    "(println \"==========================================================\")\n",
    "(first (filter #(= (:title %) \"Tel Aviv\") songs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre processing, cleaning up some badly-scraped songs & dups, we get: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "total after processing: 60\n",
      "sanity check: true\n",
      "==========================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nil"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(require '[clojure.set :as set])\n",
    "\n",
    "(def badly-scraped #{\"После стольких лет\", \"Az Halachti\", \"Khaverot Shelakh\", \"Noetset Mabat\", \"Sheket\", \"Mahapecha Shel Simha\"})\n",
    "\n",
    "(def dup-songs-starts-text \"Hi margisha\")\n",
    "\n",
    "(defn pre-process [songs]\n",
    "    (->> songs\n",
    "         (remove #(or (contains? badly-scraped (:title %))\n",
    "                      (s/starts-with? (:text %) dup-songs-starts-text)))))\n",
    "\n",
    "(def songs (pre-process scraped-songs))\n",
    "(def titles (map :title songs))\n",
    "\n",
    "(println \"==========================================================\")\n",
    "(println \"total after processing:\" (count songs))\n",
    "(println \"sanity check:\"(set/subset? #{\"I give thanks\", \"Bucharest\", \"Your girl-friends\"} (set titles)))\n",
    "(println \"==========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## examing the corpus, we can see that most of the songs have normal structure and are separated by <font color=\"red\"> [space, \",\"] </font>,\n",
    "\n",
    "## while small amount of songs like: in \"your-girlfirneds\" and \"thousand-times\", we can see different lines like:\n",
    "\n",
    "* <font size =3 color=\"green\">\"(She) does me \"chiqi chiqi dam dam\" like this all day.\"\n",
    "* \"and she has character, (it's) son of a...*\"\n",
    "* \"The square(=floor) is on fire, all the ladies are dancing\"</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this implies how we should cut (tokenize) the strings (songs), removing symbols like: <font color=\"red\"> ['=', '()', '='] & more </font>, while splitting with spaces, commas.\n",
    "\n",
    "## after removing all english-stop-words, we have count occurrences and get a simple word-count (Bag of words) from omer's songs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"dont\" 112] [\"im\" 99] [\"love\" 98] [\"come\" 77] [\"like\" 75] [\"heart\" 60] [\"day\" 60] [\"youre\" 58] [\"end\" 47] [\"go\" 43])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(require '[clojure.string :as s])\n",
    "\n",
    "(defn tokenize [text]\n",
    "  (as-> text t\n",
    "        (s/trim t)\n",
    "        (filter #(or (Character/isSpace %) (Character/isLetter ^Character %)) t)\n",
    "        (apply str t)\n",
    "        (s/lower-case t)\n",
    "        (s/split t #\"\\s+\")))\n",
    "\n",
    "(def stops (->> (slurp \"stopwords\") s/split-lines set))\n",
    "\n",
    "(defn bow [corpus]\n",
    "  (->> corpus\n",
    "       (reduce (fn [m doc]\n",
    "                 (merge-with + m (-> doc \n",
    "                                     :text\n",
    "                                     tokenize \n",
    "                                     frequencies)))\n",
    "               {})))\n",
    "\n",
    "; =================================\n",
    "(def freq-dist\n",
    "    (as-> songs songs\n",
    "          (bow songs)\n",
    "          (select-keys songs \n",
    "                       (set/difference (set (keys songs)) stops))\n",
    "          (sort-by val > songs)))\n",
    "\n",
    "(take 10 freq-dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# so our pipeline so far:  \n",
    "#### <font color=\"red\">array of songs -> tokenize-each-song -> count frequencies -> collect to result</font>, \n",
    "### plotting it with vega (cool viz grammer - <font color=\"green\">just define your viz in JSON</font> and run it in every language you want, no python-matplotlib-dependency!!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <div id='uuid-2b2e89b8-1497-46a1-bb3b-103cb968d525'></div>\n",
       "  <script>\n",
       "  requirejs.config({\n",
       "    baseUrl: 'https://cdn.jsdelivr.net/npm/',\n",
       "    paths: {\n",
       "      'vega-embed':  'vega-embed@3?noext',\n",
       "      'vega-lib': 'vega-lib?noext',\n",
       "      'vega-lite': 'vega-lite@2?noext',\n",
       "      'vega': 'vega@3?noext'\n",
       "    }\n",
       "  });\n",
       "  require(['vega-embed'], function(vegaEmbed) {\n",
       "    let spec = {\"title\":\"distribution of words in omer's corpus\",\"data\":{\"values\":[{\"freq\":112,\"word\":\"dont\"},{\"freq\":99,\"word\":\"im\"},{\"freq\":98,\"word\":\"love\"},{\"freq\":77,\"word\":\"come\"},{\"freq\":75,\"word\":\"like\"},{\"freq\":60,\"word\":\"heart\"},{\"freq\":60,\"word\":\"day\"},{\"freq\":58,\"word\":\"youre\"},{\"freq\":47,\"word\":\"end\"},{\"freq\":43,\"word\":\"go\"},{\"freq\":40,\"word\":\"know\"},{\"freq\":39,\"word\":\"one\"},{\"freq\":39,\"word\":\"night\"},{\"freq\":38,\"word\":\"give\"},{\"freq\":38,\"word\":\"get\"}]},\"mark\":\"bar\",\"encoding\":{\"x\":{\"field\":\"word\",\"type\":\"ordinal\",\"sort\":\"x\"},\"y\":{\"field\":\"freq\",\"type\":\"quantitative\"}}};\n",
       "    vegaEmbed('#uuid-2b2e89b8-1497-46a1-bb3b-103cb968d525', spec, {defaultStyle:true}).catch(console.warn);\n",
       "    }, function(err) {\n",
       "    console.log('Failed to load');\n",
       "  });\n",
       "  </script>\n",
       "</div>\n",
       "  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "; =================================\n",
    "(helper/add-dependencies '[metasoarous/oz \"1.5.0\"])\n",
    "(require '[oz.notebook.clojupyter :as oz])\n",
    "; =================================\n",
    "\n",
    "(defn xs->vega-map [xs]\n",
    "    (map #(hash-map :freq (val %) :word (key %)) xs))\n",
    "\n",
    "(def viz-data (xs->vega-map (take 30 freq-dist)))\n",
    "\n",
    "(def stacked-bar \n",
    "    {:title \"distribution of words in omer's corpus\"\n",
    "     :data {:values (take 15 viz-data)}\n",
    "     :mark \"bar\"\n",
    "     :encoding {:x {:field \"word\"\n",
    "                    :type \"ordinal\"\n",
    "                    :sort \"x\"}\n",
    "                :y {:field \"freq\"\n",
    "                    :type \"quantitative\"}}})\n",
    "\n",
    "(def word-cloud\n",
    "    {:data {:values viz-data\n",
    "            :name \"data\"}\n",
    "     :marks [{:type \"text\"\n",
    "              :from {:data \"data\"}\n",
    "              :encode {:enter {:text {:field \"word\"\n",
    "                                      :baseline {:value \"alphabetic\"}\n",
    "                                      :align {:value \"center\"}}}}\n",
    "             :transform [{:type \"wordcloud\"\n",
    "                          :size [800, 400]\n",
    "                          :text {:field \"word\"}\n",
    "                          :font \"Helvetica Neue, Arial\"\n",
    "                          :fontSize {:field \"datum.freq\"}\n",
    "                          :fontSizeRange [10, 120]\n",
    "                          :padding 2}]}]})\n",
    "; =================================\n",
    "(oz/view! stacked-bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# or in a word cloud.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <div id='uuid-efed4db2-ace7-4ec4-a4fe-261605d18055'></div>\n",
       "  <script>\n",
       "  requirejs.config({\n",
       "    baseUrl: 'https://cdn.jsdelivr.net/npm/',\n",
       "    paths: {\n",
       "      'vega-embed':  'vega-embed@3?noext',\n",
       "      'vega-lib': 'vega-lib?noext',\n",
       "      'vega-lite': 'vega-lite@2?noext',\n",
       "      'vega': 'vega@3?noext'\n",
       "    }\n",
       "  });\n",
       "  require(['vega-embed'], function(vegaEmbed) {\n",
       "    let spec = {\"data\":{\"values\":[{\"freq\":112,\"word\":\"dont\"},{\"freq\":99,\"word\":\"im\"},{\"freq\":98,\"word\":\"love\"},{\"freq\":77,\"word\":\"come\"},{\"freq\":75,\"word\":\"like\"},{\"freq\":60,\"word\":\"heart\"},{\"freq\":60,\"word\":\"day\"},{\"freq\":58,\"word\":\"youre\"},{\"freq\":47,\"word\":\"end\"},{\"freq\":43,\"word\":\"go\"},{\"freq\":40,\"word\":\"know\"},{\"freq\":39,\"word\":\"one\"},{\"freq\":39,\"word\":\"night\"},{\"freq\":38,\"word\":\"give\"},{\"freq\":38,\"word\":\"get\"},{\"freq\":36,\"word\":\"back\"},{\"freq\":36,\"word\":\"always\"},{\"freq\":36,\"word\":\"say\"},{\"freq\":35,\"word\":\"eyes\"},{\"freq\":35,\"word\":\"time\"},{\"freq\":34,\"word\":\"away\"},{\"freq\":34,\"word\":\"lets\"},{\"freq\":34,\"word\":\"want\"},{\"freq\":33,\"word\":\"us\"},{\"freq\":30,\"word\":\"forget\"},{\"freq\":30,\"word\":\"see\"},{\"freq\":30,\"word\":\"well\"},{\"freq\":29,\"word\":\"tell\"},{\"freq\":29,\"word\":\"every\"},{\"freq\":29,\"word\":\"together\"}],\"name\":\"data\"},\"marks\":[{\"type\":\"text\",\"from\":{\"data\":\"data\"},\"encode\":{\"enter\":{\"text\":{\"field\":\"word\",\"baseline\":{\"value\":\"alphabetic\"},\"align\":{\"value\":\"center\"}}}},\"transform\":[{\"type\":\"wordcloud\",\"size\":[800,400],\"text\":{\"field\":\"word\"},\"font\":\"Helvetica Neue, Arial\",\"fontSize\":{\"field\":\"datum.freq\"},\"fontSizeRange\":[10,120],\"padding\":2}]}]};\n",
       "    vegaEmbed('#uuid-efed4db2-ace7-4ec4-a4fe-261605d18055', spec, {defaultStyle:true}).catch(console.warn);\n",
       "    }, function(err) {\n",
       "    console.log('Failed to load');\n",
       "  });\n",
       "  </script>\n",
       "</div>\n",
       "  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(oz/view! word-cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a more interesting approach would be to look on the \"context\" of the words and not on their frequency (count),\n",
    "\n",
    "#### looking on the neighberhood of a word (the words [surrounding it](https://en.wikipedia.org/wiki/Distributional_semantics#Distributional_hypothesis)) can help us understand the word meaning,\n",
    "\n",
    "#### for example \n",
    "* <font color=\"green\">\"I ate sabich today\"\n",
    "* \"Sigal made a delicious sabich for us\"\n",
    "* \"Sabich should be served in pita\"</font>\n",
    "\n",
    "#### a window of size 3 (word's before/after) and word 'Sabich', we get (removing stopwords),  <font color=\"red\"> ['ate', 'made', 'delicious', 'served']</font>\n",
    "\n",
    "#### and can 'feel' it's in the context of food, ofcourse this needs to be 'learned' on loads of data (sentences...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we can build for each word a vector, which will contain it neighbours (it context), this is <font color=\"red\">word-embeddings</font>, and it's cool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     1     2     3     4     5     6     7]\r\n",
      " [0.000 0.000 0.000 1.000 0.000 2.000 1.000 0.000]\r\n",
      " [0.000 0.000 0.000 0.000 0.000 1.000 0.000 1.000]\r\n",
      " [0.000 0.000 0.000 0.000 0.000 2.000 2.000 1.000]\r\n",
      " [1.000 0.000 0.000 0.000 0.000 1.000 1.000 0.000]\r\n",
      " [0.000 0.000 0.000 0.000 0.000 2.000 1.000 2.000]\r\n",
      " [2.000 1.000 2.000 1.000 2.000 0.000 3.000 3.000]\r\n",
      " [1.000 0.000 2.000 1.000 1.000 3.000 0.000 0.000]\r\n",
      " [0.000 1.000 1.000 0.000 2.000 3.000 0.000 0.000]]\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\"banda\" 0, \"bebe\" 1, \"bote\" 2, \"di\" 3, \"solte\" 4, \"te\" 5, \"y\" 6, \"yo\" 7}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "; =================================\n",
    "(helper/add-dependencies '[net.mikera/core.matrix \"0.62.0\"])\n",
    "(helper/add-dependencies '[net.mikera/vectorz-clj \"0.48.0\"])\n",
    "(require '[clojure.core.matrix :as m])\n",
    "(m/set-current-implementation :vectorz)\n",
    "; =================================\n",
    "\n",
    "(defn distinct-words [nested-v]\n",
    "  (->> nested-v (mapcat #(identity %)) set))\n",
    "\n",
    "(defn inc' [M [x y]]\n",
    "  (m/mset M x y \n",
    "        (inc (m/mget M x y))))\n",
    "\n",
    "(defn occurrence-indices [corpus word->idx n]\n",
    "  (mapcat (fn [line]\n",
    "            (mapcat (fn [[w & words]]\n",
    "                      (map #(vector (word->idx w) (word->idx %)) words))\n",
    "                    (partition (inc n) 1 line))) corpus))\n",
    "\n",
    "(defn co-occurrence-matrix [corpus n]\n",
    "  (let [word->idx (zipmap (sort (distinct-words corpus)) (range))\n",
    "        shape (vec (repeat 2 (count word->idx)))\n",
    "        M (->> (occurrence-indices corpus word->idx n)\n",
    "               (reduce (fn [M' loc]\n",
    "                         (-> (inc' M' loc)\n",
    "                             (inc' (reverse loc))))\n",
    "                       (m/zero-array shape)))]\n",
    "    {:M         M\n",
    "     :word->idx word->idx}))\n",
    "\n",
    "; =================================\n",
    "\n",
    "(defn print' [M]\n",
    "    (m/pm M {:column-names? true}))\n",
    "\n",
    "(def ex [\"Bebe yo te bote y te bote\", \n",
    "         \"Te di banda y te solte, yo te solte\"])\n",
    "\n",
    "(def res (co-occurrence-matrix (mapv tokenize ex) 2))\n",
    "(print' (:M res))\n",
    "(:word->idx res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## so we have built a big square nXn matrix, with N=numOfWordsInCorpus, where each row is a word-vector, which represents the count of it neighbours in a fixed window-size (let's say 3). so our Dimension is N, and it's big, \n",
    "\n",
    "### reducing the dim would let us plot/feel the vectors, in 2-3 dimension,\n",
    "\n",
    "### a cool feature of matrices is that any real nXm matrix can be decomposed into SVD (3x other matrices...), and doing some other manipulations on the SVD result we can get a reduced dimensions of our matrix. (also called PCA)\n",
    "\n",
    "### there are other options for performing dim-reduction (tSNE), but will stick to it, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.793  1.055]\r\n",
      " [0.987  0.286]\r\n",
      " [2.435  0.204]\r\n",
      " [1.263  0.096]\r\n",
      " [2.397  0.159]\r\n",
      " [4.499 -3.336]\r\n",
      " [3.178  1.851]\r\n",
      " [2.897  2.055]]\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nil"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(require '[clojure.core.matrix.linear :as lm])\n",
    "\n",
    "(defn reduce-to-dim [k M]\n",
    "  (let [{:keys [U S]} (lm/svd M)\n",
    "        U' (->> U \n",
    "                m/columns\n",
    "                (take k) \n",
    "                m/transpose)\n",
    "        S' (->> S \n",
    "                (take k) \n",
    "                m/diagonal-matrix)]\n",
    "    (m/mmul U' S')))\n",
    "\n",
    "; =================================\n",
    "(m/pm (reduce-to-dim 2 (:M res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#'user/plot-embeddings"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "; =================================\n",
    "(helper/add-dependencies '[incanter \"1.9.3\"])\n",
    "(use '(incanter core stats charts io))\n",
    "; =================================\n",
    "\n",
    "\n",
    "(defn plot-embeddings [M word->idx title words]\n",
    "  (let [indices (vals (select-keys word->idx words))\n",
    "        sliced (m/emap #(m/select M % :all) indices)\n",
    "        x-cors (m/get-column sliced 0)\n",
    "        y-cors (m/get-column sliced 1)\n",
    "        plot (scatter-plot x-cors y-cors\n",
    "                           :title title\n",
    "                           :x-label \"X\"\n",
    "                           :y-label \"Y\")]\n",
    "    (doseq [[x y w] (map list x-cors y-cors words)]\n",
    "      (add-text plot x (+ 0.06 y) w))                       \n",
    "    (.createBufferedImage plot 600 400)))\n",
    "\n",
    "; =================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now using this co-occurrence matrix, we can get the most 'similar' words, which will have same 'context', using cosine-similarity as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(defn cosine-sim [v1 v2]\n",
    "  (m/div\n",
    "    (m/dot v1 v2)\n",
    "    (m/dot (lm/norm v1) (lm/norm v2))))\n",
    "\n",
    "(defn similarity [M word->idx w1 w2]\n",
    "  (cosine-sim (m/get-row M (word->idx w1))\n",
    "              (m/get-row M (word->idx w2))))\n",
    "\n",
    "(defn similar-words [M word->idx w n]\n",
    "  (let [words (keys (dissoc word->idx w))\n",
    "        sim (for [w' words]\n",
    "              (similarity M word->idx w w'))]\n",
    "    (->> (zipmap sim words)\n",
    "         (sort-by >)\n",
    "         (take n)\n",
    "         vals)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Clojure (clojupyter=0.3.2=1)",
   "language": "clojure",
   "name": "conda-clojupyter"
  },
  "language_info": {
   "file_extension": ".clj",
   "mimetype": "text/x-clojure",
   "name": "clojure",
   "version": "1.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
